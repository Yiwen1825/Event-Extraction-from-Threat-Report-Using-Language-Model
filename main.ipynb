{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'data'\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):  \n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if '|' in line:\n",
    "                    parts = line.rsplit('|', 1)\n",
    "                    if parts[1].strip() == \"\":\n",
    "                        continue\n",
    "                    text = parts[0].strip()\n",
    "                    label = parts[1].strip() if len(parts) > 1 else 'O'  \n",
    "                    texts.append(text)\n",
    "                    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 10209,\n",
       "         'AttackRansom': 1494,\n",
       "         'AttackRansom, AttackDatabreach': 24,\n",
       "         'DiscoverVulnerability': 1467,\n",
       "         'AttackDatabreach': 1405,\n",
       "         'PatchVulnerability': 949,\n",
       "         'AttackPhishing': 1283,\n",
       "         'PatchVulnerability, DiscoverVulnerability': 83,\n",
       "         'DiscoverVulnerability , PatchVulnerability': 40,\n",
       "         'DiscoverVulnerability, PatchVulnerability': 121,\n",
       "         'AttackPhishing, AttackDatabreach': 26,\n",
       "         'AttackDatabreach, AttackPhishing': 21,\n",
       "         'DiscoverVulnerability, AttackDatabreach': 22,\n",
       "         'PatchVulnerability, AttackRansom': 4,\n",
       "         'PatchVulnerability , DiscoverVulnerability': 9,\n",
       "         'DiscoverVulnerability, AttackPhishing': 2,\n",
       "         'AttackRansom, AttackDatabreach, AttackPhishing': 1,\n",
       "         'AttackDatabreach, AttackRansom': 14,\n",
       "         'PatchVulnerability , AttackDatabreach': 1,\n",
       "         'AttackDatabreach, DiscoverVulnerability': 8,\n",
       "         'AttackDatabreach, PatchVulnerability': 3,\n",
       "         'AttackRansom, DiscoverVulnerability': 1,\n",
       "         'AttackPhishing, PatchVulnerability': 6,\n",
       "         'PatchVulnerability,  DiscoverVulnerability': 1,\n",
       "         'DiscoverVulnerability,PatchVulnerability': 1,\n",
       "         'AttackPhishing , AttackRansom': 4,\n",
       "         'AttackDatabreach , AttackRansom': 11,\n",
       "         'AttackDatabreach , DiscoverVulnerability': 2,\n",
       "         'AttackPhishing , AttackDatabreach': 9,\n",
       "         'AttackRansom, AttackPhishing': 3,\n",
       "         'AttackDatabreach , AttackPhishing': 6,\n",
       "         'AttackPhishing , PatchVulnerability': 1,\n",
       "         'PatchVulnerability , AttackRansom': 1,\n",
       "         'AttackRansom , AttackDatabreach': 6,\n",
       "         'AttackRansom, PatchVulnerability': 2,\n",
       "         'PatchVulnerability, AttackPhishing': 3,\n",
       "         'DiscoverVulnerability, AttackRansom': 2,\n",
       "         'DiscoverVulnerability , AttackDatabreach': 8,\n",
       "         'PatchVulnerability, AttackDatabreach': 1,\n",
       "         'AttackPhishing, AttackRansom': 6,\n",
       "         'AttackPhishing, AttackRansom, PatchVulnerability': 1,\n",
       "         'DiscoverVulnerability , AttackRansom': 1,\n",
       "         'AttackRansom , DiscoverVulnerability': 2,\n",
       "         'AttackRansom , AttackDatabreach , AttackRansom': 1,\n",
       "         'AttackRansom , PatchVulnerability': 1,\n",
       "         'AttackDatabreach , AttackDatabreach': 1,\n",
       "         'AttackPhishing, DiscoverVulnerability': 1,\n",
       "         'AttackRansom , AttackPhishing': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp  = []\n",
    "for label in labels:\n",
    "    for t in label.split(','):\n",
    "        temp.append(t.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 10209,\n",
       "         'AttackRansom': 1581,\n",
       "         'AttackDatabreach': 1571,\n",
       "         'DiscoverVulnerability': 1771,\n",
       "         'PatchVulnerability': 1228,\n",
       "         'AttackPhishing': 1374})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>AttackDatabreach</th>\n",
       "      <th>AttackPhishing</th>\n",
       "      <th>AttackRansom</th>\n",
       "      <th>DiscoverVulnerability</th>\n",
       "      <th>PatchVulnerability</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attackers start wiping data from CouchDB and H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Researchers are now observing similar destruct...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Security researchers Victor Gevers and Niall M...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The two have put together spreadsheets on Goog...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the case of Hadoop, a framework used for di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17264</th>\n",
       "      <td>\"Ransomware has become a billion-dollar cash c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17265</th>\n",
       "      <td>In order to help prevent falling victim to ran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17266</th>\n",
       "      <td>Launched in 2016, the No More Ransom scheme br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17267</th>\n",
       "      <td>The portal is available in 29 languages and si...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17268</th>\n",
       "      <td>The release of GandCrab decryption tools comes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17269 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  AttackDatabreach  \\\n",
       "0      Attackers start wiping data from CouchDB and H...                 0   \n",
       "1      Researchers are now observing similar destruct...                 0   \n",
       "2      Security researchers Victor Gevers and Niall M...                 0   \n",
       "3      The two have put together spreadsheets on Goog...                 0   \n",
       "4      In the case of Hadoop, a framework used for di...                 0   \n",
       "...                                                  ...               ...   \n",
       "17264  \"Ransomware has become a billion-dollar cash c...                 0   \n",
       "17265  In order to help prevent falling victim to ran...                 0   \n",
       "17266  Launched in 2016, the No More Ransom scheme br...                 0   \n",
       "17267  The portal is available in 29 languages and si...                 0   \n",
       "17268  The release of GandCrab decryption tools comes...                 0   \n",
       "\n",
       "       AttackPhishing  AttackRansom  DiscoverVulnerability  \\\n",
       "0                   0             0                      0   \n",
       "1                   0             0                      0   \n",
       "2                   0             0                      0   \n",
       "3                   0             0                      0   \n",
       "4                   0             0                      0   \n",
       "...               ...           ...                    ...   \n",
       "17264               0             0                      0   \n",
       "17265               0             0                      0   \n",
       "17266               0             1                      0   \n",
       "17267               0             0                      0   \n",
       "17268               0             0                      0   \n",
       "\n",
       "       PatchVulnerability  O  \n",
       "0                       0  1  \n",
       "1                       0  1  \n",
       "2                       0  1  \n",
       "3                       0  1  \n",
       "4                       0  1  \n",
       "...                   ... ..  \n",
       "17264                   0  1  \n",
       "17265                   0  1  \n",
       "17266                   0  0  \n",
       "17267                   0  1  \n",
       "17268                   0  1  \n",
       "\n",
       "[17269 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Text': texts,\n",
    "    'Label': labels\n",
    "})\n",
    "\n",
    "all_labels = [\"AttackDatabreach\", \"AttackPhishing\", \"AttackRansom\", \"DiscoverVulnerability\", \"PatchVulnerability\",\"O\"]\n",
    "\n",
    "\n",
    "def label_columns(row, label_list):\n",
    "    label_data = {label: 0 for label in label_list}\n",
    "    entries = row['Label'].split(',')\n",
    "    for entry in entries:\n",
    "        entry = entry.strip()\n",
    "        if entry in label_data:\n",
    "            label_data[entry] = 1\n",
    "    return pd.Series(label_data)\n",
    "\n",
    "label_df = df.apply(lambda row: label_columns(row, all_labels), axis=1)\n",
    "\n",
    "\n",
    "final_df = pd.concat([df['Text'], label_df], axis=1)\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'AttackDatabreach': 0, 'AttackPhishing': 1, 'AttackRansom': 2, 'DiscoverVulnerability': 3, 'PatchVulnerability': 4, 'O': 5}\n",
      "id2label: {0: 'AttackDatabreach', 1: 'AttackPhishing', 2: 'AttackRansom', 3: 'DiscoverVulnerability', 4: 'PatchVulnerability', 5: 'O'}\n"
     ]
    }
   ],
   "source": [
    "labels = [\"AttackDatabreach\", \"AttackPhishing\", \"AttackRansom\", \"DiscoverVulnerability\", \"PatchVulnerability\", \"O\"]\n",
    "\n",
    "# Create label2id dictionary\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Create id2label dictionary\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "# Output the dictionaries\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is1ab/anaconda3/envs/coref/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/is1ab/anaconda3/envs/coref/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mt111599004\u001b[0m (\u001b[33mntut-biolab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/is1ab/code/Event-Extraction-from-Cyber-Threat-Report-Using-BERT-Model/wandb/run-20240713_141624-nogtgx1w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ntut-biolab/huggingface/runs/nogtgx1w' target=\"_blank\">devoted-cherry-146</a></strong> to <a href='https://wandb.ai/ntut-biolab/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ntut-biolab/huggingface' target=\"_blank\">https://wandb.ai/ntut-biolab/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ntut-biolab/huggingface/runs/nogtgx1w' target=\"_blank\">https://wandb.ai/ntut-biolab/huggingface/runs/nogtgx1w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='259' max='1296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 259/1296 03:54 < 15:45, 1.10 it/s, Epoch 0.60/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "dataset = Dataset.from_pandas(final_df)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert integer labels to floats for BCEWithLogitsLoss\n",
    "def format_labels(example):\n",
    "    labels = [float(example[col]) for col in ['AttackDatabreach', 'AttackPhishing', 'AttackRansom', \n",
    "                                              'DiscoverVulnerability', 'PatchVulnerability', 'O']]\n",
    "    return {'labels': labels}\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(format_labels)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_testvalid = tokenized_datasets.train_test_split(test_size=0.2, shuffle=True)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, shuffle=True)\n",
    "train_dataset = train_testvalid['train']\n",
    "valid_dataset = test_valid['train']\n",
    "test_dataset = test_valid['test']\n",
    "\n",
    "# Metrics computation\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Apply sigmoid function to logits and threshold at 0.5 for binary prediction\n",
    "    preds = (1 / (1 + np.exp(-logits)) > 0.5).astype(float)\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# Training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6, problem_type=\"multi_label_classification\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "trainer.evaluate(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
